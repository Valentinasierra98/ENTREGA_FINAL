{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "\n",
    "ruta_archivo1 = 'C:\\\\Users\\\\valen\\\\OneDrive\\\\Documentos\\\\VALEN UAO\\\\ETI\\\\ACTIVIDAD1\\\\BASE_DE_TRABAJO_SABER11.xlsx'\n",
    "\n",
    "df1=pd.read_excel(ruta_archivo1)\n",
    "ruta_archivo2 = 'C:\\\\Users\\\\valen\\\\OneDrive\\\\Documentos\\\\VALEN UAO\\\\ETI\\\\ACTIVIDAD1\\\\COMPLETA-CARACTERIZACIÓN EST PRIMER SEMESTRE (1) - copia.xlsx'\n",
    "\n",
    "df2=pd.read_excel(ruta_archivo2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "# Función para remover tildes de los nombres de las columnas\n",
    "def remover_tildes_columnas(df):\n",
    "    df.columns = [unidecode(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# Aplicar la función a ambas bases de datos\n",
    "df1 = remover_tildes_columnas(df1)\n",
    "df2 = remover_tildes_columnas(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que la columna clave tenga el mismo nombre en ambas bases\n",
    "df1.rename(columns={\"Codigo Estudiante\": \"codigo_estudiante\"}, inplace=True)\n",
    "df2.rename(columns={\"Codigo Estudiante\": \"codigo_estudiante\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar df1 con la información de df2 usando \"codigo_estudiante\" como clave\n",
    "# Se mantiene toda la información de df1 y se agregan datos coincidentes de df2\n",
    "df_final = pd.merge(df1, df2, on=\"codigo_estudiante\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "# Normalizar nombres de columnas en df_final sin corchetes\n",
    "df_final.columns = [\n",
    "    unidecode(col).replace(' ', '_').replace('-', '_').replace('.', '_')\n",
    "    for col in df_final.columns\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "# Normalizar nombres de columnas en df_final sin corchetes\n",
    "df_final.columns = [unidecode(col).replace(\" \", \"_\") for col in df_final.columns]\n",
    "\n",
    "# Crear la estructura de la tabla con los tipos de datos (sin corchetes `[]`)\n",
    "columnas_sql = \", \".join([\n",
    "    f\"{col}\" if df_final[col].dtype == \"O\" else f\"{col} FLOAT\"\n",
    "    for col in df_final.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "\n",
    "#conexión con la BD\n",
    "conn = pymssql.connect(\n",
    "    server='127.0.0.1',\n",
    "    user='sa',\n",
    "    password='12345678',\n",
    "    #database='master1',\n",
    "    as_dict= False\n",
    ")\n",
    "\n",
    "# Se crea el cursor para manejo de qwery\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos 'Actividad_ETL' creada.\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva base de datos en SQL Server\n",
    "db_name = \"Actividad_ETL\"\n",
    "\n",
    "try:\n",
    "    # Se verifica que no haya transacciones activas en la base de datos\n",
    "    cur.execute(\"IF @@TRANCOUNT > 0 ROLLBACK TRANSACTION\")\n",
    "\n",
    "    # Se consulta si la base de datos ya existe en el sistema\n",
    "    cur.execute(f\"SELECT name FROM sys.databases WHERE name = '{db_name}'\")\n",
    "    \n",
    "    # Se obtiene el resultado de la consulta\n",
    "    resultado = cur.fetchone()\n",
    "\n",
    "    # Si la base de datos ya existe, se muestra un mensaje\n",
    "    if resultado:\n",
    "        print(f\"La base de datos '{db_name}' ya existe.\")\n",
    "    else:\n",
    "        # Si la base de datos no existe, se crea con CREATE DATABASE\n",
    "        cur.execute(f\"CREATE DATABASE {db_name}\")\n",
    "        print(f\"Base de datos '{db_name}' creada.\")\n",
    "\n",
    "# Captura cualquier error que ocurra durante la ejecución del código\n",
    "except Exception as e:\n",
    "    print(f\"Error al verificar o crear la base de datos: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'tabla_etl_nueva1' creada exitosamente en la base de datos 'Actividad_ETL'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Nombre de la nueva tabla\n",
    "new_tb_name = \"tabla_etl_nueva1\"\n",
    "\n",
    "try:\n",
    "    # Función para limpiar nombres de columnas y evitar errores de SQL\n",
    "    def limpiar_nombre(col):\n",
    "        col = col.strip().replace(' ', '_')  # Reemplazar espacios por guion bajo\n",
    "        col = re.sub(r'[^a-zA-Z0-9_]', '', col)  # Eliminar caracteres especiales\n",
    "        return col[:128]  # Limitar a 128 caracteres máximo\n",
    "\n",
    "    # Construcción de la definición de columnas SQL\n",
    "    columnas_sql = \", \".join([\n",
    "        f\"[{limpiar_nombre(col)}] NVARCHAR(MAX)\" if df_final[col].dtype == \"O\" \n",
    "        else f\"[{limpiar_nombre(col)}] FLOAT\"\n",
    "        for col in df_final.columns\n",
    "    ])\n",
    "\n",
    "    # Query para crear la tabla si no existe\n",
    "    sql_query = f\"\"\"\n",
    "    IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES \n",
    "                   WHERE TABLE_NAME = '{new_tb_name}' AND TABLE_SCHEMA = 'dbo') \n",
    "    BEGIN \n",
    "        CREATE TABLE dbo.{new_tb_name} ({columnas_sql}) \n",
    "    END\n",
    "    \"\"\"\n",
    "\n",
    "    cur.execute(sql_query)\n",
    "\n",
    "    print(f\"Tabla '{new_tb_name}' creada exitosamente en la base de datos 'Actividad_ETL'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al crear la tabla: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La tabla 'tabla_etl_nueva1' existe en la base de datos.\n",
      " Insertando datos en la tabla 'tabla_etl_nueva1'...\n",
      " Se han insertado 11729 filas en la tabla 'tabla_etl_nueva1'.\n"
     ]
    }
   ],
   "source": [
    "import pymssql\n",
    "\n",
    "#conexión con la BD\n",
    "conn = pymssql.connect(\n",
    "    server='127.0.0.1',\n",
    "    user='sa',\n",
    "    password='12345678',\n",
    "    database='Actividades_ETL',\n",
    "    as_dict= False\n",
    ")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # 1. Verificar si la tabla existe en la base de datos\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'tabla_etl_nueva1'\")\n",
    "    existe = cur.fetchone()[0]\n",
    "\n",
    "    if existe == 0:\n",
    "        print(\"La tabla 'tabla_etl_nueva1' no existe en la base de datos.\")\n",
    "    else:\n",
    "        print(\" La tabla 'tabla_etl_nueva1' existe en la base de datos.\")\n",
    "\n",
    "        # 2. Insertar los datos en la tabla\n",
    "        print(\" Insertando datos en la tabla 'tabla_etl_nueva1'...\")\n",
    "\n",
    "        # Reemplazar NaN con None para evitar errores en SQL Server\n",
    "        df_final_clean = df_final.replace({np.nan: None})\n",
    "\n",
    "        # Construcción de la consulta de inserción\n",
    "        columnas = \", \".join([f\"[{col.replace(' ', '_')}]\" for col in df_final_clean.columns])\n",
    "        valores_placeholder = \", \".join([\"%s\"] * len(df_final_clean.columns))\n",
    "\n",
    "        insert_query = f\"INSERT INTO tabla_etl_nueva1 ({columnas}) VALUES ({valores_placeholder})\"\n",
    "\n",
    "        # Convertir DataFrame a lista de tuplas para inserción\n",
    "        datos_a_insertar = [tuple(row) for row in df_final_clean.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Insertar datos en lotes\n",
    "        cur.executemany(insert_query, datos_a_insertar)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\" Se han insertado {len(df_final_clean)} filas en la tabla 'tabla_etl_nueva1'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\" Error al insertar datos en la tabla: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
