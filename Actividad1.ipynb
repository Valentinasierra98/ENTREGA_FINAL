{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "\n",
    "ruta_archivo1 = 'C:\\\\Users\\\\valen\\\\OneDrive\\\\Documentos\\\\VALEN UAO\\\\ETI\\\\ACTIVIDAD1\\\\BASE_DE_TRABAJO_SABER11.xlsx'\n",
    "\n",
    "df1=pd.read_excel(ruta_archivo1)\n",
    "ruta_archivo2 = 'C:\\\\Users\\\\valen\\\\OneDrive\\\\Documentos\\\\VALEN UAO\\\\ETI\\\\ACTIVIDAD1\\\\COMPLETA-CARACTERIZACIÓN EST PRIMER SEMESTRE (1) - copia.xlsx'\n",
    "\n",
    "df2=pd.read_excel(ruta_archivo2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "# Función para remover tildes de los nombres de las columnas\n",
    "def remover_tildes_columnas(df):\n",
    "    df.columns = [unidecode(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# Aplicar la función a ambas bases de datos\n",
    "df1 = remover_tildes_columnas(df1)\n",
    "df2 = remover_tildes_columnas(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que la columna clave tenga el mismo nombre en ambas bases\n",
    "df1.rename(columns={\"Codigo Estudiante\": \"codigo_estudiante\"}, inplace=True)\n",
    "df2.rename(columns={\"Codigo Estudiante\": \"codigo_estudiante\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar df1 con la información de df2 usando \"codigo_estudiante\" como clave\n",
    "# Se mantiene toda la información de df1 y se agregan datos coincidentes de df2\n",
    "df_final = pd.merge(df1, df2, on=\"codigo_estudiante\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "# Normalizar nombres de columnas en df_final sin corchetes\n",
    "df_final.columns = [\n",
    "    unidecode(col).replace(' ', '_').replace('-', '_').replace('.', '_')\n",
    "    for col in df_final.columns\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "# Normalizar nombres de columnas en df_final sin corchetes\n",
    "df_final.columns = [unidecode(col).replace(\" \", \"_\") for col in df_final.columns]\n",
    "\n",
    "# Crear la estructura de la tabla con los tipos de datos (sin corchetes `[]`)\n",
    "columnas_sql = \", \".join([\n",
    "    f\"{col}\" if df_final[col].dtype == \"O\" else f\"{col} FLOAT\"\n",
    "    for col in df_final.columns\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "\n",
    "#conexión con la BD\n",
    "conn = pymssql.connect(\n",
    "    server='127.0.0.1',\n",
    "    user='sa',\n",
    "    password='12345678',\n",
    "    #database='master1',\n",
    "    as_dict= False\n",
    ")\n",
    "\n",
    "# Se crea el cursor para manejo de qwery\n",
    "cur = conn.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La base de datos 'Actividades_ETL4' ya existe.\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva base de datos en SQL Server\n",
    "db_name = \"Actividades_ETL4\"\n",
    "\n",
    "try:\n",
    "    # Se verifica que no haya transacciones activas en la base de datos\n",
    "    cur.execute(\"IF @@TRANCOUNT > 0 ROLLBACK TRANSACTION\")\n",
    "\n",
    "    # Se consulta si la base de datos ya existe en el sistema\n",
    "    cur.execute(f\"SELECT name FROM sys.databases WHERE name = '{db_name}'\")\n",
    "    \n",
    "    # Se obtiene el resultado de la consulta\n",
    "    resultado = cur.fetchone()\n",
    "\n",
    "    # Si la base de datos ya existe, se muestra un mensaje\n",
    "    if resultado:\n",
    "        print(f\"La base de datos '{db_name}' ya existe.\")\n",
    "    else:\n",
    "        # Si la base de datos no existe, se crea con CREATE DATABASE\n",
    "        cur.execute(f\"CREATE DATABASE {db_name}\")\n",
    "        print(f\"Base de datos '{db_name}' creada.\")\n",
    "\n",
    "# Captura cualquier error que ocurra durante la ejecución del código\n",
    "except Exception as e:\n",
    "    print(f\"Error al verificar o crear la base de datos: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'tabla_etl_nueva1' creada exitosamente en la base de datos 'Actividades_ETL4'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Nombre de la nueva tabla\n",
    "new_tb_name = \"tabla_etl_nueva1\"\n",
    "\n",
    "try:\n",
    "    # Función para limpiar nombres de columnas y evitar errores de SQL\n",
    "    def limpiar_nombre(col):\n",
    "        col = col.strip().replace(' ', '_')  # Reemplazar espacios por guion bajo\n",
    "        col = re.sub(r'[^a-zA-Z0-9_]', '', col)  # Eliminar caracteres especiales\n",
    "        return col[:128]  # Limitar a 128 caracteres máximo\n",
    "\n",
    "    # Construcción de la definición de columnas SQL\n",
    "    columnas_sql = \", \".join([\n",
    "        f\"[{limpiar_nombre(col)}] NVARCHAR(MAX)\" if df_final[col].dtype == \"O\" \n",
    "        else f\"[{limpiar_nombre(col)}] FLOAT\"\n",
    "        for col in df_final.columns\n",
    "    ])\n",
    "\n",
    "    # Query para crear la tabla si no existe\n",
    "    sql_query = f\"\"\"\n",
    "    IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES \n",
    "                   WHERE TABLE_NAME = '{new_tb_name}' AND TABLE_SCHEMA = 'dbo') \n",
    "    BEGIN \n",
    "        CREATE TABLE dbo.{new_tb_name} ({columnas_sql}) \n",
    "    END\n",
    "    \"\"\"\n",
    "\n",
    "    cur.execute(sql_query)\n",
    "\n",
    "    print(f\"Tabla '{new_tb_name}' creada exitosamente en la base de datos 'Actividades_ETL4'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al crear la tabla: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La tabla 'tabla_etl_nueva1' existe en la base de datos.\n",
      " Insertando datos en la tabla 'tabla_etl_nueva'...\n",
      " Error al insertar datos en la tabla: name 'np' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Verificar si la tabla existe en la base de datos\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'tabla_etl_nueva1'\")\n",
    "    existe = cur.fetchone()[0]\n",
    "\n",
    "    if existe == 0:\n",
    "        print(\"La tabla 'tabla_etl_nueva1' no existe en la base de datos.\")\n",
    "    else:\n",
    "        print(\" La tabla 'tabla_etl_nueva1' existe en la base de datos.\")\n",
    "\n",
    "        # 2. Insertar los datos en la tabla\n",
    "        print(\" Insertando datos en la tabla 'tabla_etl_nueva'...\")\n",
    "\n",
    "        # Reemplazar NaN con None para evitar errores en SQL Server\n",
    "        df_final_clean = df_final.replace({np.nan: None})\n",
    "\n",
    "        # Construcción de la consulta de inserción\n",
    "        columnas = \", \".join([f\"[{col.replace(' ', '_')}]\" for col in df_final_clean.columns])\n",
    "        valores_placeholder = \", \".join([\"%s\"] * len(df_final_clean.columns))\n",
    "\n",
    "        insert_query = f\"INSERT INTO tabla_etl_nueva1 ({columnas}) VALUES ({valores_placeholder})\"\n",
    "\n",
    "        # Convertir DataFrame a lista de tuplas para inserción\n",
    "        datos_a_insertar = [tuple(row) for row in df_final_clean.itertuples(index=False, name=None)]\n",
    "\n",
    "        # Insertar datos en lotes\n",
    "        cur.executemany(insert_query, datos_a_insertar)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\" Se han insertado {len(df_final_clean)} filas en la tabla 'tabla_etl_nueva1'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\" Error al insertar datos en la tabla: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Se han insertado 11729 filas en la tabla 'tabla_etl_nueva1'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # Convertir NaN a None para que SQL Server los acepte\n",
    "    df_final_clean = df_final.replace({np.nan: None})\n",
    "\n",
    "    # Función para limpiar nombres de columnas\n",
    "    def limpiar_nombre(col):\n",
    "        col = col.strip().replace(' ', '_')  # Reemplazar espacios por guion bajo\n",
    "        col = re.sub(r'[^a-zA-Z0-9_]', '', col)  # Eliminar caracteres especiales\n",
    "        return col[:128]  # Limitar a 128 caracteres máximo\n",
    "\n",
    "    # Aplicar la función a los nombres de las columnas\n",
    "    columnas_limpias = [f\"[{limpiar_nombre(col)}]\" for col in df_final_clean.columns]\n",
    "\n",
    "    # Construcción de la consulta SQL\n",
    "    columnas_sql = \", \".join(columnas_limpias)\n",
    "    valores_placeholder = \", \".join([\"%s\"] * len(df_final_clean.columns))\n",
    "\n",
    "    insert_query = f\"INSERT INTO tabla_etl_nueva1 ({columnas_sql}) VALUES ({valores_placeholder})\"\n",
    "\n",
    "    # Convertir DataFrame a lista de tuplas para la inserción\n",
    "    datos_a_insertar = [tuple(row) for row in df_final_clean.itertuples(index=False, name=None)]\n",
    "\n",
    "    # Ejecutar la inserción en lotes\n",
    "    cur.executemany(insert_query, datos_a_insertar)\n",
    "    conn.commit()  # Confirmar la transacción\n",
    "\n",
    "    print(f\" Se han insertado {len(df_final_clean)} filas en la tabla 'tabla_etl_nueva1'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error al insertar datos: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "\n",
    "#conexión con la BD\n",
    "conn = pymssql.connect(\n",
    "    server='127.0.0.1',\n",
    "    user='sa',\n",
    "    password='12345678',\n",
    "    database='Actividades_ETL4',\n",
    "    as_dict= False\n",
    ")\n",
    "\n",
    "# Se crea el cursor para manejo de qwery\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla 'tabla_etl_nueva1' existe en la base de datos.\n",
      "La tabla tiene 11729 filas.\n",
      "Primeros 5 registros de la tabla:\n",
      "(2195323.0, 'AC201910033951', '2019', '20191', 430.3846153846154, 430.3846153846154, 83.0, 81.0, 100.0, 80.0, 87.0, '5.B+', '2019-3', 2019.0, 'Masculino', 18.0, '[15-19]', 'Soltero', 5.0, 'Cali', 'Colombia', 'Cali', 55170.0, 'INGENIERIA ELECTRONICA Y TELECOMUNICACIONES', 'INGENIERIA ELECTRONICA Y TELECOMUNICACIONES-55170', 'EKT', 'EK06', 'REGULAR', 'INGENIERIA', 'Universitario', 'PRESENCIAL', 376001013441.0, 'COLEGIO BILINGÜE DIANA OESE', 'Valle Del Cauca', 'Cali', 'NO OFICIAL', 'A+', 'Registro Alta Calidad', 'AC201910033951', '2019-3')\n",
      "(22501672.0, 'AC202433990587', '20243', '20243', 425.0, 425.0, 81.0, 81.0, 100.0, 79.0, 81.0, '5.B+', '2025-21', 2025.0, 'Masculino', 17.0, '[15-19]', 'Soltero', 3.0, 'CALI', 'COLOMBIA', 'CALI', 110364.0, 'INGENIERIA INFORMATICA', 'INGENIERIA INFORMATICA-110364', 'ISH', 'ISGB', 'DIGICAMPUS', 'INGENIERIA Y CIENCIAS BASICAS', 'Universitario', 'VIRTUAL', 176001022360.0, 'INSTITUCION EDUCATIVA TECNICA COMERCIAL LAS AMERICAS', 'Valle Del Cauca', 'CALI', 'OFICIAL', 'B', 'Registro Alta Calidad', 'AC202433990587', '2025-1')\n",
      "(22500852.0, 'AC202433990587', '20243', '20243', 425.0, 425.0, 81.0, 81.0, 100.0, 79.0, 81.0, '5.B+', '2025-1', 2025.0, 'Masculino', 17.0, '[15-19]', 'Soltero', 3.0, 'CALI', 'COLOMBIA', 'CALI', 20151.0, 'INGENIERIA BIOMEDICA', 'INGENIERIA BIOMEDICA-20151', 'BM', 'BM04', 'REGULAR', 'INGENIERIA Y CIENCIAS BASICAS', 'Universitario', 'PRESENCIAL', 176001022360.0, 'INSTITUCION EDUCATIVA TECNICA COMERCIAL LAS AMERICAS', 'Valle Del Cauca', 'CALI', 'OFICIAL', 'B', 'Registro Alta Calidad', 'AC202433990587', '2025-1')\n",
      "(2225642.0, 'AC202210102103', '2022', '20221', 428.46153846153845, 428.46153846153845, 81.0, 83.0, 100.0, 78.0, 88.0, '5.B+', '2022-3', 2022.0, 'Masculino', 19.0, '[15-19]', 'Soltero', 5.0, 'Cali', 'Colombia', 'Cali', 20151.0, 'INGENIERIA BIOMEDICA', 'INGENIERIA BIOMEDICA-20151', 'BM', 'BM04', 'REGULAR', 'INGENIERIA', 'Universitario', 'PRESENCIAL', 376001013441.0, 'COLEGIO BILINGÜE DIANA OESE', 'Valle Del Cauca', 'Cali', 'NO OFICIAL', 'A+', 'Registro Alta Calidad', 'AC202210102103', '2022-3')\n",
      "(22500327.0, 'AC202431499839', '20243', '20243', 443.0, 443.0, 78.0, 100.0, 100.0, 77.0, 87.0, '5.B+', '2025-1', 2025.0, 'Femenino', 17.0, '[15-19]', 'Soltero', 2.0, 'POPAYAN', 'COLOMBIA', 'POPAYAN', 20115.0, 'INGENIERIA INFORMATICA', 'INGENIERIA INFORMATICA-20115', 'IS', 'IS06', 'REGULAR', 'INGENIERIA Y CIENCIAS BASICAS', 'Universitario', 'PRESENCIAL', 119001000052.0, 'INSTITUCION EDUCATIVA NUESTRA SEÑORA DEL CARMEN-CAUCA', 'Cauca', 'POPAYAN', 'OFICIAL', 'A+', 'Registro Alta Calidad', 'AC202431499839', '2025-1')\n",
      "Esquema de la tabla:\n",
      "Columna: codigo_estudiante, Tipo de dato: float\n",
      "Columna: Registro_SNP, Tipo de dato: nvarchar\n",
      "Columna: Periodo_Presentacion1, Tipo de dato: nvarchar\n",
      "Columna: Periodo_Presentacion, Tipo de dato: nvarchar\n",
      "Columna: Puntaje_Global_ICFES, Tipo de dato: float\n",
      "Columna: A_Global, Tipo de dato: float\n",
      "Columna: A_Lectura_Critica, Tipo de dato: float\n",
      "Columna: A_Matematicas, Tipo de dato: float\n",
      "Columna: A_Sociales_y_Ciudadanas, Tipo de dato: float\n",
      "Columna: A_Ciencias_Naturales, Tipo de dato: float\n",
      "Columna: A_Ingles, Tipo de dato: float\n",
      "Columna: A_Nivel_Ingles, Tipo de dato: nvarchar\n",
      "Columna: Periodo_Academico, Tipo de dato: nvarchar\n",
      "Columna: Ano, Tipo de dato: float\n",
      "Columna: Genero, Tipo de dato: nvarchar\n",
      "Columna: Edad, Tipo de dato: float\n",
      "Columna: Rango_Edad, Tipo de dato: nvarchar\n",
      "Columna: Estado_Civil, Tipo de dato: nvarchar\n",
      "Columna: Estrato_Economico, Tipo de dato: float\n",
      "Columna: Municipio_Nacimiento, Tipo de dato: nvarchar\n",
      "Columna: Pais_Nacimiento, Tipo de dato: nvarchar\n",
      "Columna: Ciudad_Residencia, Tipo de dato: nvarchar\n",
      "Columna: SNIES, Tipo de dato: float\n",
      "Columna: Programa1, Tipo de dato: nvarchar\n",
      "Columna: Programa, Tipo de dato: nvarchar\n",
      "Columna: Cod_Programa, Tipo de dato: nvarchar\n",
      "Columna: Plan, Tipo de dato: nvarchar\n",
      "Columna: Tipo_Oferta, Tipo de dato: nvarchar\n",
      "Columna: FACULTAD, Tipo de dato: nvarchar\n",
      "Columna: Nivel_de_Formacion, Tipo de dato: nvarchar\n",
      "Columna: Modalidad_Programa, Tipo de dato: nvarchar\n",
      "Columna: Codigo_Dane, Tipo de dato: float\n",
      "Columna: Colegio, Tipo de dato: nvarchar\n",
      "Columna: Departamento_Colegio, Tipo de dato: nvarchar\n",
      "Columna: Ciudad_Colegio, Tipo de dato: nvarchar\n",
      "Columna: Colegio_Sector, Tipo de dato: nvarchar\n",
      "Columna: Colegio_Clasificacion, Tipo de dato: nvarchar\n",
      "Columna: Reconocimiento_del_ministerio, Tipo de dato: nvarchar\n",
      "Columna: SNP, Tipo de dato: nvarchar\n",
      "Columna: PERIODO_REGULAR, Tipo de dato: nvarchar\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Verificar si la tabla existe en la base de datos\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'tabla_etl_nueva1'\")\n",
    "    existe = cur.fetchone()[0]\n",
    "    \n",
    "    if existe == 0:\n",
    "        print(\"La tabla 'tabla_etl_nueva1' no existe en la base de datos.\")\n",
    "    else:\n",
    "        print(\"La tabla 'tabla_etl_nueva1' existe en la base de datos.\")\n",
    "\n",
    "        # 2. Contar cuántas filas tiene la tabla\n",
    "        cur.execute(\"SELECT COUNT(*) FROM tabla_etl_nueva1\")\n",
    "        num_filas = cur.fetchone()[0]\n",
    "        print(f\"La tabla tiene {num_filas} filas.\")\n",
    "\n",
    "        # 3. Ver los primeros 5 registros de la tabla\n",
    "        cur.execute(\"SELECT TOP 5 * FROM tabla_etl_nueva1\")\n",
    "        filas = cur.fetchall()\n",
    "        print(\"Primeros 5 registros de la tabla:\")\n",
    "        for fila in filas:\n",
    "            print(fila)\n",
    "\n",
    "        # 4. Ver el esquema de la tabla\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT COLUMN_NAME, DATA_TYPE\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = 'tabla_etl_nueva1'\n",
    "        \"\"\")\n",
    "        columnas = cur.fetchall()\n",
    "        print(\"Esquema de la tabla:\")\n",
    "        for col in columnas:\n",
    "            print(f\"Columna: {col[0]}, Tipo de dato: {col[1]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Error al consultar la tabla: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
